Args in experiment:
Namespace(model='informer', data='custom', root_path='/Users/phamnam/Downloads/Informer2020-main-3/data_cleaned', data_path='Cleaned_Gold_monthly.csv', features='S', target='Price', freq='b', checkpoints='./checkpoints/', seq_len=48, label_len=48, pred_len=12, enc_in=1, dec_in=1, c_out=1, d_model=128, n_heads=4, e_layers=1, d_layers=2, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='test', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='b')
Use CPU
>>>>>>>start training : informer_custom_ftS_sl48_ll48_pl12_dm128_nh4_el1_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 239
val 33
test 74
Epoch: 1 cost time: 6.773735046386719
Epoch: 1, Steps: 7 | Train Loss: 0.5425323 Vali Loss: 1.4312981 Test Loss: 0.4358463
Validation loss decreased (inf --> 1.431298).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 7.872009038925171
Epoch: 2, Steps: 7 | Train Loss: 0.2001461 Vali Loss: 0.4856567 Test Loss: 0.6743481
Validation loss decreased (1.431298 --> 0.485657).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 9.139034986495972
Epoch: 3, Steps: 7 | Train Loss: 0.1423996 Vali Loss: 0.4404622 Test Loss: 0.7253343
Validation loss decreased (0.485657 --> 0.440462).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 9.79651403427124
Epoch: 4, Steps: 7 | Train Loss: 0.1223925 Vali Loss: 0.5864977 Test Loss: 0.5872204
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 9.781292200088501
Epoch: 5, Steps: 7 | Train Loss: 0.1072564 Vali Loss: 0.6774106 Test Loss: 0.5871973
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 9.21841287612915
Epoch: 6, Steps: 7 | Train Loss: 0.1010538 Vali Loss: 0.6634707 Test Loss: 0.4840198
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : informer_custom_ftS_sl48_ll48_pl12_dm128_nh4_el1_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 74
test shape: (2, 32, 12, 1) (2, 32, 12, 1)
test shape: (64, 12, 1) (64, 12, 1)
mse:0.7293146252632141, mae:0.7477725148200989
Use CPU
>>>>>>>start training : informer_custom_ftS_sl48_ll48_pl12_dm128_nh4_el1_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 239
val 33
test 74
Epoch: 1 cost time: 9.55595326423645
Epoch: 1, Steps: 7 | Train Loss: 0.3875930 Vali Loss: 1.8795538 Test Loss: 0.3977929
Validation loss decreased (inf --> 1.879554).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 9.639397859573364
Epoch: 2, Steps: 7 | Train Loss: 0.1738805 Vali Loss: 0.3673498 Test Loss: 0.8739472
Validation loss decreased (1.879554 --> 0.367350).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 9.1427640914917
Epoch: 3, Steps: 7 | Train Loss: 0.1351920 Vali Loss: 0.3452203 Test Loss: 0.8596050
Validation loss decreased (0.367350 --> 0.345220).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 8.827760219573975
Epoch: 4, Steps: 7 | Train Loss: 0.1080334 Vali Loss: 0.5674376 Test Loss: 0.6053334
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 6.502326011657715
Epoch: 5, Steps: 7 | Train Loss: 0.0996022 Vali Loss: 0.6718214 Test Loss: 0.5235018
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 6.691502094268799
Epoch: 6, Steps: 7 | Train Loss: 0.0925041 Vali Loss: 0.6473030 Test Loss: 0.5323330
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : informer_custom_ftS_sl48_ll48_pl12_dm128_nh4_el1_dl2_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 74
test shape: (2, 32, 12, 1) (2, 32, 12, 1)
test shape: (64, 12, 1) (64, 12, 1)
mse:0.8229365348815918, mae:0.7939042448997498
